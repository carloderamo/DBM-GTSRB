!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.transformer_dataset.TransformerDataset {
        raw: !pkl: "%(data_path)s/preprocessed_train.pkl",
        transformer: !pkl: "%(grbm_path)s/grbm_gtsrb.pkl"
    },
    model: !obj:pylearn2.models.dbm.DBM {
        batch_size: %(batch_size)i,
        niter: 10,
        inference_procedure: !obj:pylearn2.models.dbm.WeightDoubling {},
        visible_layer: !obj:pylearn2.models.dbm.BinaryVector {
            nvis: %(nvis)i,
        },
        hidden_layers: [
            !obj:pylearn2.models.dbm.BinaryVectorMaxPool {
                layer_name: 'h1',
                detector_layer_dim: %(detector_layer_1_dim)i,
                pool_size: 1,
                irange: 0.001,
            },
            !obj:pylearn2.models.dbm.BinaryVectorMaxPool {
                layer_name: 'h2',
                detector_layer_dim: %(detector_layer_2_dim)i,
                pool_size: 1,
                irange: 0.001,
            },
        ],
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: %(batch_size)i,
        learning_rate: 0.0005,
        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
            init_momentum: 0.5,
        },
        monitoring_dataset: *train,
        cost : !obj:pylearn2.costs.cost.SumOfCosts {
            costs: [
                !obj:pylearn2.costs.dbm.VariationalPCD {
                    num_chains: 100,
                    num_gibbs_steps: 5,
                },
                !obj:pylearn2.costs.dbm.WeightDecay {
                    coeffs: [ .001, .001 ],
                },
#                !obj:pylearn2.costs.dbm.TorontoSparsity {
#                    targets: [ .2, .1 ],
#                    coeffs: [ .001, .001 ],
#                }
            ],
        },
        termination_criterion: !obj:pylearn2.termination_criteria.EpochCounter { 
            max_epochs: %(max_epochs)i
        },
#        update_callbacks: [
#            !obj:pylearn2.training_algorithms.sgd.CustomizedLROverEpoch {
#            }
#        ]
    },
    extensions: [
        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
            final_momentum: 0.9,
            start: 1,
            saturate: 6,
        }
    ],
    save_path: "%(save_path)s/dbm_gtsrb.pkl",
    save_freq : %(max_epochs)i
}
